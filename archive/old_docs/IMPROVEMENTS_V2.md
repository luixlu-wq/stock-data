# Stock Prediction Model - Version 2.0 Improvements

**Date**: 2026-01-03
**Status**: ‚úÖ All improvements implemented, retraining in progress

---

## üéØ **Goals**

Address the severe underfitting problem where the model was:
- Predicting only 10.6% of actual variance
- Correlation = 0.069 (essentially random)
- Directional accuracy = 54.31% (barely better than coin flip)

**Target Performance**:
- R¬≤ > 0.15 (meaningful predictions)
- Directional accuracy > 58%
- Prediction variance > 40% of true variance

---

## üîß **IMPROVEMENTS IMPLEMENTED**

### **1. Custom Directional Loss Functions** ‚úÖ

**Problem**: Huber loss encourages conservative predictions (predicting near mean minimizes loss)

**Solution**: Implemented 3 new loss functions in [`src/models/losses.py`](src/models/losses.py):

#### **A. DirectionalHuberLoss** (SELECTED)
```python
total_loss = (1 - weight) * huber_loss + weight * directional_penalty
```
- **Huber component**: Robust magnitude accuracy
- **Directional component**: Penalizes wrong direction
- **Weight** (0.3): 70% magnitude, 30% direction

**Benefits**:
- Encourages correct sign prediction
- Still robust to outliers
- Balances accuracy and direction

#### **B. WeightedDirectionalLoss**
```python
loss = base_loss * magnitude_weights * directional_penalty
```
- Weights large moves more heavily
- Encourages model to predict big movements
- Useful for volatile stocks

#### **C. QuantileLoss**
- Predicts distribution (10th, 50th, 90th percentiles)
- Better uncertainty quantification
- For future research

**Configuration**:
```yaml
loss:
  regression: "directional_huber"  # NEW!
  directional_weight: 0.3  # 30% directional, 70% magnitude
  magnitude_scale: 2.0  # Encourage larger predictions
```

---

### **2. Reduced Prediction Horizon** ‚úÖ

**Change**: 5-day ‚Üí **1-day** ahead prediction

**Reasoning**:
- Shorter horizons are more predictable
- Less noise accumulation
- Market microstructure more stable

**Expected Impact**:
- Higher R¬≤ (0.15-0.25 vs 0.003)
- Better directional accuracy (58-62% vs 54%)

**Configuration**:
```yaml
data:
  prediction_horizon: 1  # Changed from 5
```

---

### **3. Increased Model Capacity** ‚úÖ

**Problem**: Model may be too simple to capture complex stock patterns

**Changes**:
| Parameter | Old Value | New Value | Reasoning |
|-----------|-----------|-----------|-----------|
| `hidden_size` | 128 | **192** | +50% capacity for complex patterns |
| `dropout` | 0.2 | **0.25** | Slightly more regularization |

**Expected Impact**:
- Better feature extraction
- More expressive representations
- Captures non-linear patterns

---

### **4. Optimized Training Hyperparameters** ‚úÖ

**A. Learning Rate**
- **Old**: 0.0005 (too conservative)
- **New**: 0.0008 (+60%)
- **Reasoning**: Faster convergence, less underfitting

**B. Weight Decay**
- **Old**: 0.00001
- **New**: 0.000005 (50% reduction)
- **Reasoning**: Less regularization ‚Üí larger predictions

**C. Learning Rate Warmup**
- **Old**: 10 epochs
- **New**: 5 epochs
- **Reasoning**: Faster warmup, more time at full LR

**D. Early Stopping**
- **Patience**: 15 ‚Üí **25** epochs
- **Min delta**: 0.00001 ‚Üí **0.000005**
- **Reasoning**: Allow more training, accept tiny improvements

**E. Max Epochs**
- **Old**: 50
- **New**: 100
- **Reasoning**: Give model more time to learn

**F. LR Scheduler**
- **Patience**: 10 ‚Üí **12** epochs
- **Min LR**: 0.000001 ‚Üí **0.0000001**
- **Reasoning**: More patient, allow finer tuning

---

## üìä **EXPECTED PERFORMANCE COMPARISON**

### **Before (Version 1.0)**
```
Model Metrics:
  RMSE: 0.0411
  MAE:  0.0291
  R¬≤:   0.0028  ‚Üê Nearly useless
  Dir Acc: 54.31%  ‚Üê Barely better than random

Prediction Behavior:
  Pred std: 0.0044  ‚Üê Way too conservative
  True std: 0.041
  Variance ratio: 0.1065 (10.6%)  ‚Üê Severe underfitting
  Correlation: 0.069  ‚Üê Essentially random

Training:
  Loss function: Huber (conservative)
  Prediction horizon: 5 days (harder)
  Hidden size: 128 (limited capacity)
```

### **After (Version 2.0 - Expected)**
```
Model Metrics:
  RMSE: ~0.015-0.020  (better on 1-day)
  MAE:  ~0.012-0.016
  R¬≤:   0.15-0.25  ‚Üê Meaningful predictions!
  Dir Acc: 58-62%  ‚Üê Profitable edge

Prediction Behavior:
  Pred std: ~0.015-0.020  ‚Üê More aggressive
  True std: ~0.025 (1-day is less volatile than 5-day)
  Variance ratio: 0.50-0.70 (50-70%)  ‚Üê Much better!
  Correlation: 0.30-0.50  ‚Üê Actual signal

Training:
  Loss function: DirectionalHuberLoss (direction-aware)
  Prediction horizon: 1 day (easier)
  Hidden size: 192 (more capacity)
```

---

## üî¨ **EVALUATION METHODOLOGY**

### **Phase 1: Basic Metrics**
```python
# Standard regression metrics
- RMSE (should be < 0.020 for 1-day returns)
- MAE (should be < 0.016)
- R¬≤ (should be > 0.15)
- MAPE (percentage error)
- Directional accuracy (should be > 58%)
```

### **Phase 2: Distribution Analysis**
```python
# Check if model is still too conservative
variance_ratio = pred_std / true_std
# Target: 0.50-0.70 (was 0.106)

correlation = np.corrcoef(y_true, y_pred)[0,1]
# Target: 0.30-0.50 (was 0.069)
```

### **Phase 3: Directional Analysis**
```python
# Breakdown by direction
correct_up = (y_true > 0) & (y_pred > 0)
correct_down = (y_true < 0) & (y_pred < 0)

# Should see:
- Directional accuracy > 58%
- Balanced performance (not just guessing all UP)
```

### **Phase 4: Advanced Analysis**
```python
# Trading simulation
- Sharpe ratio (risk-adjusted returns)
- Maximum drawdown
- Win rate
- Profit factor

# Targets:
- Sharpe > 0.5 (decent)
- Win rate > 52%
- Profit factor > 1.2
```

---

## üîç **WHAT TO MONITOR DURING TRAINING**

### **1. Loss Progression**
```
Epoch 1-5:   Warmup (loss should decrease slowly)
Epoch 6-20:  Rapid learning (loss drops significantly)
Epoch 21-40: Refinement (smaller improvements)
Epoch 41+:   Fine-tuning (may trigger early stopping)
```

### **2. Red Flags**
- ‚ö†Ô∏è Loss stops decreasing after epoch 10 ‚Üí underfitting still present
- ‚ö†Ô∏è Model collapse warning ‚Üí predictions becoming constant again
- ‚ö†Ô∏è Prediction variance < 0.01 ‚Üí too conservative still

### **3. Good Signs**
- ‚úÖ Validation loss steadily decreasing
- ‚úÖ No model collapse warnings
- ‚úÖ Training progresses beyond 20 epochs
- ‚úÖ Prediction variance > 0.015

---

## üìÅ **FILES MODIFIED**

### **New Files**
1. **[src/models/losses.py](src/models/losses.py)** - Custom loss functions
   - `DirectionalHuberLoss`
   - `WeightedDirectionalLoss`
   - `QuantileLoss`

### **Modified Files**
1. **[src/models/trainer.py](src/models/trainer.py:59-83)** - Added loss function support
   - Imports custom losses
   - Handles `directional_huber` and `weighted_directional` loss types
   - Configurable directional weight

2. **[config/config.yaml](config/config.yaml)**:
   - Line 235: `prediction_horizon: 5 ‚Üí 1`
   - Line 320: `hidden_size: 128 ‚Üí 192`
   - Line 322: `dropout: 0.2 ‚Üí 0.25`
   - Line 329: `epochs: 50 ‚Üí 100`
   - Line 330: `learning_rate: 0.0005 ‚Üí 0.0008`
   - Line 331: `weight_decay: 0.00001 ‚Üí 0.000005`
   - Line 337: `warmup.epochs: 10 ‚Üí 5`
   - Line 346: `early_stopping.patience: 15 ‚Üí 25`
   - Line 347: `early_stopping.min_delta: 0.00001 ‚Üí 0.000005`
   - Line 352: `scheduler.patience: 10 ‚Üí 12`
   - Line 358-360: Added directional loss config

3. **[src/utils/metrics.py](src/utils/metrics.py)** - Fixed earlier
   - MAPE division by zero handling
   - Auto-detect number of classes

---

## üöÄ **TRAINING STATUS**

### **Current Run**
- ‚úÖ Data reprocessed with 1-day horizon
- ‚úÖ All configurations updated
- üîÑ **Training in progress** (started 20:27)
- ‚è≥ Expected completion: ~45-60 minutes

### **Monitoring**
```bash
# Check training progress
tail -f training_improved.log

# Or check latest epochs
tail -50 logs/stock_data.log
```

### **After Training Completes**
```bash
# Evaluate
python main.py eval-reg

# Check predictions
python -c "import pandas as pd; df=pd.read_parquet('data/processed/regression_predictions.parquet'); print(df['y_pred'].describe())"
```

---

## üéØ **SUCCESS CRITERIA**

### **Minimum Acceptable**
- ‚úÖ R¬≤ > 0.10 (better than baseline)
- ‚úÖ Dir Acc > 56% (profitable)
- ‚úÖ Variance ratio > 0.30
- ‚úÖ No model collapse

### **Good Performance**
- ‚úÖ R¬≤ > 0.15
- ‚úÖ Dir Acc > 58%
- ‚úÖ Variance ratio > 0.50
- ‚úÖ Correlation > 0.30

### **Excellent Performance**
- ‚úÖ R¬≤ > 0.25
- ‚úÖ Dir Acc > 62%
- ‚úÖ Variance ratio > 0.70
- ‚úÖ Correlation > 0.50

---

## üîÑ **NEXT STEPS AFTER EVALUATION**

### **If Performance is Good (R¬≤ > 0.15)**
1. Train multi-task model for even better results
2. Create diagnostic visualizations
3. Implement backtesting framework
4. Deploy for live predictions

### **If Performance is Moderate (0.10 < R¬≤ < 0.15)**
1. Try `weighted_directional` loss (more aggressive)
2. Increase `directional_weight` to 0.4-0.5
3. Increase `magnitude_scale` to 3.0-5.0
4. Try bidirectional LSTM

### **If Performance is Still Poor (R¬≤ < 0.10)**
1. Stock returns may be too noisy for simple LSTM
2. Consider:
   - Transformer architecture
   - Ensemble methods
   - Alternative features (sentiment, options flow)
   - Focus on specific stocks or sectors only

---

## üìö **REFERENCES**

- [TRAINING_ISSUES_AND_FIXES.md](TRAINING_ISSUES_AND_FIXES.md) - Original issues
- [src/models/losses.py](src/models/losses.py) - Custom loss implementations
- [config/config.yaml](config/config.yaml) - Updated configuration

---

**Summary**: All recommended improvements have been implemented. The model now uses directional loss, predicts 1-day ahead, has more capacity, and is trained with optimized hyperparameters. Training is in progress - expect significantly better results!
